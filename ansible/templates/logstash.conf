# to test, run logstash like this:
# cd {{ logstash_home_dir }}
# ./bin/logstash -f logstash.conf --config.test_and_exit
# ./bin/logstash -f logstash.conf

input {
    file {
        path => "{{ rsyslog_tgt_file }}"
        #start_position => "beginning" #prob not necessary after finding out about sincedb null trick
        #sincedb_path => "/dev/null" for testing (to read from beginning of file)
    }
}

filter {
    # parse generic log data
    grok {
        match => { "message" => "%{SYSLOGBASE}" }
        add_tag => [ "syslog" ]
    }
    # add default datastream info
    if "syslog" in [tags] {
        mutate { 
            add_field => {
                "[data_stream][type]" => "logs"
                "[data_stream][dataset]" => "rsyslog"
                "[data_stream][namespace]" => "default"
            }
        }
    }
    # parse haproxy data
    if [process][name] == "haproxy" {
        grok {
            match => { "message" => "%{HAPROXYTCP}" }
            add_tag => [ "haproxy-tcp" ]
        }
        grok {
            match => { "message" => "%{HAPROXYHTTP}" }
            add_tag => [ "haproxy-http" ]
        }
        
        # add more specific datastream info
        mutate { 
            replace => { "[data_stream][dataset]" => "haproxy" }
        }
        if "haproxy-tcp" in [tags] {
            mutate { 
                replace => { "[data_stream][namespace]" => "tcp" }
            }
        }
        if "haproxy-http" in [tags] {
            mutate { 
                replace => { "[data_stream][namespace]" => "http" }
            }
        }
    }
}

output {
    # elastic search saves the incoming data into "data streams"
    # - they are automatically created if they don't exist
    # - names are determined via data_stream_auto_routing
    elasticsearch { hosts => "localhost:9200" }
    #stdout { codec => rubydebug }
}
