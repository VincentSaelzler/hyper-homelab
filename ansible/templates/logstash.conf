input {
    # useful to testing, to see what rsyslog is sending.
    # file {
    #     path => "{{ rsyslog_tgt_file }}"
    #     sincedb_path => "/dev/null" for testing (to read from beginning of file)
    # }
    # receive via TCP from rsyslog
    tcp { port => 12833 }
}

filter {
    # parse generic log data
    grok {
        match => { "message" => "%{SYSLOGBASE}" }
        add_tag => [ "syslog" ]
    }
    # add default datastream info
    if "syslog" in [tags] {
        mutate { 
            add_field => {
                "[data_stream][type]" => "logs"
                "[data_stream][dataset]" => "rsyslog"
                "[data_stream][namespace]" => "default"
            }
        }
    }
    # parse haproxy data
    if [process][name] == "haproxy" {
        grok {
            match => { "message" => "%{HAPROXYTCP}" }
            add_tag => [ "haproxy-tcp" ]
            tag_on_failure => []
        }
        grok {
            match => { "message" => "%{HAPROXYHTTP}" }
            add_tag => [ "haproxy-http" ]
            tag_on_failure => []
        }
        
        # add more specific datastream info
        mutate { 
            replace => { "[data_stream][dataset]" => "haproxy" }
        }
        if "haproxy-tcp" in [tags] {
            mutate { 
                replace => { "[data_stream][namespace]" => "tcp" }
            }
        }
        if "haproxy-http" in [tags] {
            mutate { 
                replace => { "[data_stream][namespace]" => "http" }
            }
        }
    }
}

output {
    # elastic search saves the incoming data into "data streams"
    # - they are automatically created if they don't exist
    # - names are determined via data_stream_auto_routing
    elasticsearch { hosts => "localhost:9200" }
    #stdout { codec => rubydebug }
}
